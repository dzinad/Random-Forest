{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import sklearn as sk\n",
    "import sklearn.metrics\n",
    "import random as rd\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RandomForestClassifier\n",
    "Создадим класс RandomForestClassifier. Он содержит tree_num объектов типа Tree - отдельных решающих деревьев для подвыборки размера N, сгенерированной бутстрапом. Каждая вершина в Tree является объектом класса Node. В Node хранится следующая информация:<br>\n",
    "а) является ли вершина листом<br>\n",
    "б) если лист, то прогноз для листа<br>\n",
    "если не лист:<br>\n",
    "в) индекс признака, по которому в данной вершине происходит разделение<br>\n",
    "г) значение признака, по которому в данной вершине происходит разделение<br>\n",
    "д) вершины-дети<br>\n",
    "Ни в одной из вершин сами элементы подвыборки не хранятся.<br>\n",
    "Каждое решающее дерево строится по q(d) признакам (d = 784 - размер картинки). Для выбора способа разбиения вершины используется критерий Джини. Критерий останова: достижение максимальной глубины дерева или количество элементов в листе.<br>\n",
    "Метод predict для каждого дерева определяет, к какому листу должен принадлежать элемент (исходя из использованного разбиения вершины), и усредняет ответ по всем деревьям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DRandomForestClassifier(object):\n",
    "    \"\"\"docstring\"\"\"\n",
    "    \n",
    "    class Tree:\n",
    "        \"\"\"docstring\"\"\"\n",
    "        \n",
    "        class Node:\n",
    "            \"\"\"docstring\"\"\"\n",
    "            \n",
    "            def __init__(self):\n",
    "                \"\"\"Constructor\"\"\"\n",
    "                self.is_leaf = False\n",
    "                self.forecast = None\n",
    "                self.t = 0\n",
    "                self.factor_ind = 0\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "                \n",
    "            def predict(self, X):\n",
    "                if self.is_leaf:\n",
    "                    return self.forecast\n",
    "                if X[0][self.factor_ind] <= self.t:\n",
    "                    if self.left is not None:\n",
    "                        return self.left.predict(X)\n",
    "                    else:\n",
    "                        return self.right.predict(X)\n",
    "                else:\n",
    "                    if self.right is not None:\n",
    "                        return self.right.predict(X)\n",
    "                    else:\n",
    "                        return self.left.predict(X)\n",
    "                    \n",
    "        \n",
    "        def __init__(self, X, y, max_in_leaf, max_depth, q):            \n",
    "            \"\"\"Constructor\"\"\"        \n",
    "            self.max_in_leaf = max_in_leaf\n",
    "            self.max_depth = max_depth\n",
    "            self.root = self.Node()\n",
    "            X = np.array(X).reshape((len(X), 1, -1))\n",
    "            d = len(X[0][0])\n",
    "            tmp = np.arange(d)\n",
    "            s = int (q(d))\n",
    "            np.random.shuffle(tmp)\n",
    "            self.factors = tmp[:s]\n",
    "            self.root = self.add_children(self.root, X, y, 0)\n",
    "            \n",
    "        def H(self, x, y):\n",
    "            y = np.array(y)\n",
    "            tmp1 = np.unique(y)   \n",
    "            p1 = len(y[y == tmp1[0]]) * 1. / len(x)\n",
    "            p2 = 1 - p1\n",
    "            return p1 * (1 - p1) * p2 * (1 - p2)\n",
    "        \n",
    "            \n",
    "        def add_children(self, node, X, y, depth):\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            if (len(X) <= self.max_in_leaf) | (depth >= self.max_depth):\n",
    "                values = unique(y)\n",
    "                num1 = len(y[y == values[0]])\n",
    "                num2 = 0\n",
    "                if len(values) > 1:\n",
    "                    num2 = len(y[y == values[1]])\n",
    "                if num1 > num2:\n",
    "                    node.forecast = values[0]\n",
    "                else:\n",
    "                    node.forecast = values[1]\n",
    "                node.is_leaf = True\n",
    "                return node\n",
    "            \n",
    "            factor_num = len(self.factors)\n",
    "            best_t = 0\n",
    "            best_ind = 0\n",
    "            min_err = -1\n",
    "            for i in xrange(0, factor_num):\n",
    "                factor_values = unique(X[:, :, self.factors[i]])\n",
    "                for j in xrange(0, len(factor_values)):\n",
    "                    t = factor_values[j]   \n",
    "                    xl = []\n",
    "                    yl = []\n",
    "                    xr = []\n",
    "                    yr = []\n",
    "                    for k in xrange(0, len(X)):\n",
    "                        if X[k][0][self.factors[i]] <= t:\n",
    "                            xl.append(X[k])\n",
    "                            yl.append(y[k])\n",
    "                        else:\n",
    "                            xr.append(X[k])\n",
    "                            yr.append(y[k])\n",
    "                    err = 0\n",
    "                    if len(xl) > 0:\n",
    "                        err += len(xl) * self.H(xl, yl) * 1. / len(X)\n",
    "                    if len(xr) > 0:\n",
    "                        err += len(xr) * self.H(xr, yr) * 1. / len(X)                    \n",
    "                    if (min_err == -1) | (err < min_err):\n",
    "                        min_err = err\n",
    "                        best_t = t\n",
    "                        best_ind = self.factors[i]\n",
    "                        \n",
    "            xl = []\n",
    "            yl = []\n",
    "            xr = []\n",
    "            yr = []\n",
    "            for k in xrange(0, len(X)):\n",
    "                if X[k][0][best_ind] <= best_t:\n",
    "                    xl.append(X[k])\n",
    "                    yl.append(y[k])\n",
    "                else:\n",
    "                    xr.append(X[k])\n",
    "                    yr.append(y[k])\n",
    "            node.factor_ind = best_ind\n",
    "            node.t = best_t                \n",
    "                                \n",
    "            if len(xl) > 0:\n",
    "                left = self.Node()\n",
    "                left = self.add_children(left, xl, yl, depth + 1)\n",
    "                node.left = left\n",
    "                \n",
    "            if len(xr) > 0:\n",
    "                right = self.Node()\n",
    "                right = self.add_children(right, xr, yr, depth + 1)\n",
    "                node.right = right\n",
    "                \n",
    "            return node\n",
    "        \n",
    "        def predict(self, X):\n",
    "            return self.root.predict(X)\n",
    "    \n",
    "    def __init__(self, tree_num = 10, max_in_leaf = 1, max_depth = 8, q_func = sqrt):            \n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.tree_num = tree_num\n",
    "        self.max_in_leaf = max_in_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.q_func = q_func\n",
    "        \n",
    "    def get_params(self, deep = True):\n",
    "        return {\"max_in_leaf\" : self.max_in_leaf, \"max_depth\" : self.max_depth, \"tree_num\" : self.tree_num, \"q_func\" : self.q_func}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n = len(X)\n",
    "        self.trees = []\n",
    "        self.classes = unique(y)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        for i in xrange(0, self.tree_num):\n",
    "            ind = np.random.randint(0, self.n, size = self.n, dtype = 'int')\n",
    "            self.trees.append(self.Tree(X[ind], y[ind], self.max_in_leaf, self.max_depth, self.q_func))\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X).reshape(len(X), 1, -1)\n",
    "        res = []\n",
    "        for i in xrange(0, len(X)):\n",
    "            sum = 0\n",
    "            for j in xrange(0, self.tree_num):\n",
    "                sum += self.trees[j].predict(X[i])\n",
    "            av = sum * 1. / self.tree_num\n",
    "            min_err = -1\n",
    "            best_class = 0\n",
    "            for j in xrange(0, len(self.classes)):\n",
    "                if (min_err == -1) | (abs(self.classes[j] - av) < min_err):\n",
    "                    min_err = abs(self.classes[j] - av)\n",
    "                    best_class = j\n",
    "            res.append(self.classes[best_class])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_digit(digit):\n",
    "    pyplot.imshow(digit.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор KNN из предыдущей лабораторной путался в цифрах 4/7/9 и 3/5/8.<br> \n",
    "Из данных MNIST возьмем 1000 элементов классов 3 и 5 (да, должно быть 10000, но это помогло ускорить процесс вычислений в 10 раз, что критично в случае моего классификатора). <i>Все дальнейшие исследования проводились на выборке в 1000 элементов.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('learn.csv')\n",
    "y = data['answer']\n",
    "x = data[(y == 3) | (y == 5)]\n",
    "x = x.sample(n = 1000)\n",
    "y = x['answer']\n",
    "y = y.values\n",
    "x = x.drop('answer', 1)\n",
    "x = x.iloc[:].values\n",
    "    \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = DRandomForestClassifier(tree_num = 10, max_depth = 8)\n",
    "cl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров. 1 этап\n",
    "Подберем при помощи GridSearchCV наилучшие гиперпараметры. Подбираем в 2 этапа: сначала на более широкой сетке параметров, затем на узкой сетке в окрестности лучшего результата (!!!убрать, если не успею 2 этап). Попробуем следующие варианты:<br>\n",
    "число деревьев: 5, 15, 25, 50, 75<br>\n",
    "максимальная глубина дерева: 5, 10, 15<br>\n",
    "максимальное число элементов в листе: 5, 10, 15<br>\n",
    "функция подсчета числа признаков: q = sqrt(x) - это рекомендуемая функция для задачи классификации, ее зафиксируем<br>\n",
    "<b>Результаты:</b><br>\n",
    "число деревьев: 75 (чем больше деревьев, тем точнее ответ - вроде логично)<br>\n",
    "максимальная глубина дерева: 10 (деревья не должны быть слишком глубокими, чтобы не переобучались)<br>\n",
    "максимальное число элементов в листе: 5 (их не должно быть слишком мало, чтобы не было переобучения; и не должно быть слишком много, чтобы учитывалось достаточное количество признаков)<br>\n",
    "<i>Примечание</i>. В output написано, что он считал 203 минуты, хотя на деле он считал всю ночь и закончил утром при мне, то есть часов 6-7 прошло с момента запуска. Почему так, я не поняла, может, вы в курсе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 45 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 202.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_in_leaf': 5, 'q_func': <ufunc 'sqrt'>, 'tree_num': 75}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = { \"tree_num\"      : [5, 15, 25, 50, 75],\n",
    "           \"max_depth\"         : [5, 10, 15],\n",
    "           \"max_in_leaf\"      : [5, 10, 15],\n",
    "           \"q_func\"      : [sqrt]}\n",
    "grid_search = GridSearchCV(DRandomForestClassifier(), param_grid, scoring = 'accuracy', verbose = 1, cv = 2)\n",
    "grid_search.fit(x, y)\n",
    "grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров. 2 этап\n",
    "Рассмотрим теперь следующие наборы параметров (на более узкой сетке):<br>\n",
    "число деревьев: 30 - фиксируем (ясно, что чем больше, тем лучше) так, чтобы было не очень мало, но и не очень много, а то будет долго считаться<br>\n",
    "максимальная глубина дерева: 8, 10, 12<br>\n",
    "максимальное число элементов в листе: 3, 5, 7<br>\n",
    "функция подсчета числа признаков: q = sqrt(x) - фиксируем<br>\n",
    "<b>Результаты:</b><br>\n",
    "максимальная глубина дерева: 10<br>\n",
    "максимальное число элементов в листе: 7<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 32.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_in_leaf': 7, 'q_func': <ufunc 'sqrt'>, 'tree_num': 30}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_n = { \"tree_num\"      : [30],\n",
    "           \"max_depth\"         : [8, 10, 12],\n",
    "           \"max_in_leaf\"      : [3, 5, 7],\n",
    "           \"q_func\"      : [sqrt]}\n",
    "grid_search_n = GridSearchCV(DRandomForestClassifier(), param_grid_n, scoring = 'accuracy', verbose = 1, cv = 2)\n",
    "grid_search_n.fit(x, y)\n",
    "grid_search_n.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# График ошибки в зависимости от числа деревьев\n",
    "Опять используем GridSearchCV, но для более широкого набора параметров (для числа входных деревьев). Остальные параметры фиксируем (берем рекомендуемые):<br>\n",
    "а) число элементов в листе: 5<br>\n",
    "б) максимальная глубина: 8<br>\n",
    "в) q: sqrt<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 73.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.874, 0.853, 0.917, 0.925, 0.93, 0.927, 0.944, 0.929, 0.947, 0.95]\n"
     ]
    }
   ],
   "source": [
    "tree_num_values = [5, 10, 15, 20, 25, 30, 50, 75, 100, 120]\n",
    "param_grid = { \"tree_num\"      : tree_num_values}\n",
    "grid_search = GridSearchCV(DRandomForestClassifier(), param_grid, scoring = 'accuracy', verbose = 1, cv = 2)\n",
    "grid_search.fit(x, y)\n",
    "tree_num_scores = [t[1] for t in grid_search.grid_scores_]\n",
    "err = np.array([1] * len(tree_num_scores)) - np.array(tree_num_scores)\n",
    "print tree_num_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1651da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tree_num_values, err)\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение со стандартным классификатором\n",
    "Зафиксируем гиперпараметры:<br>\n",
    "а) количество деревьев: 50<br>\n",
    "б) максимальныя глубина: 10<br>\n",
    "в) число элементов в листе: 7<br>\n",
    "<b>Результаты:</b><br>\n",
    "рукописный классификатор: 93,7%<br>\n",
    "стандартный классификатор: 95%<br>\n",
    "Следует отметить, что при хорошо подобранных гиперпараметрах RandomForest - очень хороший и достаточно универсальный классификатор, так как на этих классах другие алгоритмы путались, а RandomForest дает высокий процент точности.<br>\n",
    "Различия в accuracy со стандартным можно объяснить наличием в стандартном классификаторе большого числа других гиперпараметров, которые в рукописном игнорируются. Возможно, если и их подобрать, то можно будет еще повысить accuracy рукописного RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DRandomForestClassifier at 0xe7e8978>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl1 = DRandomForestClassifier(tree_num = 50, max_depth = 10, max_in_leaf = 7)\n",
    "cl1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93666666666666665"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cl1.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl2 = RandomForestClassifier(n_estimators = 50, max_depth = 10, min_samples_leaf = 7)\n",
    "cl2.fit(x_train, y_train)\n",
    "accuracy_score(y_test, cl2.predict(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
